{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgOPd4Tncaae"
   },
   "source": [
    "# *Quick, Draw!* GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CL2-Dw1Gcaak"
   },
   "source": [
    "In this notebook, we use Generative Adversarial Network code (adapted from [Rowel Atienza's](https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan_mnist.py) under [MIT License](https://github.com/roatienza/Deep-Learning-Experiments/blob/master/LICENSE)) to create sketches in the style of humans who have played the [*Quick, Draw!* game](https://quickdraw.withgoogle.com) (data available [here](https://github.com/googlecreativelab/quickdraw-dataset) under [Creative Commons Attribution 4.0 license](https://creativecommons.org/licenses/by/4.0/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXlK4A-bcaau"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zo2M552dcaax"
   },
   "outputs": [],
   "source": [
    "# for data input and output:\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for deep learning: \n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Reshape # new! \n",
    "from tensorflow.keras.layers import Conv2DTranspose, UpSampling2D # new! \n",
    "from tensorflow.keras.optimizers import Nadam \n",
    "\n",
    "# for plotting: \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Lg61gBKcaa7"
   },
   "source": [
    "#### Load data\n",
    "NumPy bitmap files are [here](https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap) -- pick your own drawing category -- you don't have to pick *apples* :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gd18GLyEcaa9"
   },
   "source": [
    "_If you're using Colab, the easiest way to load the data is to access it from Google Drive (detailed instructions are provided [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA))._\n",
    "\n",
    "*For example, after we downloaded the \"apple.npy\" file, we placed it in our personal Google Drive in a subdirectory called \"quickdraw_data\" within a directory called \"Colab Notebooks\" (Colab creates this directory for saving notebooks by default). [Here's a screenshot](https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/img/apples-in-drive.png) of what that looks like in the Google Drive web-browser interface. The data in place, we then ran the following (commented out) commands before executing the remainder of the notebook:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0DKADziWcabA",
    "outputId": "146c8610-fcaa-433a-ca56-22375b7e0322"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# os.chdir('/content/gdrive/My Drive/Colab Notebooks/quickdraw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejQ38dGScabE"
   },
   "outputs": [],
   "source": [
    "input_images = \"../quickdraw_data/apple.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEPP0_pZcabM"
   },
   "outputs": [],
   "source": [
    "data = np.load(input_images) # 28x28 (sound familiar?) grayscale bitmap in numpy .npy format; images are centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iMDPiztHcabT",
    "outputId": "23577e72-e3ba-4cac-c40e-f04fac8bf47c"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mf_8n9OBcaba",
    "outputId": "032d63e5-4e85-440c-bc0f-d3937894ed1f"
   },
   "outputs": [],
   "source": [
    "data[4242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GspZei4Ecabg",
    "outputId": "65200161-275a-4bee-ac2a-0ddfd8d4b938"
   },
   "outputs": [],
   "source": [
    "data = data/255\n",
    "data = np.reshape(data,(data.shape[0],28,28,1)) # fourth dimension is color\n",
    "img_w,img_h = data.shape[1:3]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FvQTNzJjcabl",
    "outputId": "1eeeaa7e-9831-48f5-ae5e-61f8d2f63427"
   },
   "outputs": [],
   "source": [
    "data[4242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "-A7Npc8lcabr",
    "outputId": "f50a4af7-74d1-4178-b58c-0722459dbfac"
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[4242,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwNAZqXCcabx"
   },
   "source": [
    "#### Create discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRNBDJ15cabz"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(depth=64, p=0.4):\n",
    "\n",
    "    # Define inputs\n",
    "    image = Input((img_w,img_h,1))\n",
    "    \n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(depth*1, 5, strides=2, \n",
    "                   padding='same', activation='relu')(image)\n",
    "    conv1 = Dropout(p)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(depth*2, 5, strides=2, \n",
    "                   padding='same', activation='relu')(conv1)\n",
    "    conv2 = Dropout(p)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(depth*4, 5, strides=2, \n",
    "                   padding='same', activation='relu')(conv2)\n",
    "    conv3 = Dropout(p)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(depth*8, 5, strides=1, \n",
    "                   padding='same', activation='relu')(conv3)\n",
    "    conv4 = Flatten()(Dropout(p)(conv4))\n",
    "    \n",
    "    # Output layer\n",
    "    prediction = Dense(1, activation='sigmoid')(conv4)\n",
    "    \n",
    "    # Model definition\n",
    "    model = Model(inputs=image, outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "iRcVYtcncab4",
    "outputId": "11462148-a76b-43d7-e2f4-454c2a170f6e"
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "M2A1U4lJcab9",
    "outputId": "c8214ac7-7986-472c-d0f0-330f90c9bc1d"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOPgsz9JcacK"
   },
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Nadam(lr=0.0008, \n",
    "                                     clipvalue=1.0), \n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3yK5JL8cacQ"
   },
   "source": [
    "#### Create generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWT37kKCcacR"
   },
   "outputs": [],
   "source": [
    "z_dimensions = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OriG0BPcacV"
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=z_dimensions, \n",
    "                    depth=64, p=0.4):\n",
    "    \n",
    "    # Define inputs\n",
    "    noise = Input((latent_dim,))\n",
    "    \n",
    "    # First dense layer\n",
    "    dense1 = Dense(7*7*depth)(noise)\n",
    "    dense1 = BatchNormalization(momentum=0.9)(dense1) # default momentum for moving average is 0.99\n",
    "    dense1 = Activation(activation='relu')(dense1)\n",
    "    dense1 = Reshape((7,7,depth))(dense1)\n",
    "    dense1 = Dropout(p)(dense1)\n",
    "    \n",
    "    # De-Convolutional layers\n",
    "    conv1 = UpSampling2D()(dense1)\n",
    "    conv1 = Conv2DTranspose(int(depth/2), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv1)\n",
    "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "    conv1 = Activation(activation='relu')(conv1)\n",
    "    \n",
    "    conv2 = UpSampling2D()(conv1)\n",
    "    conv2 = Conv2DTranspose(int(depth/4), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv2)\n",
    "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "    conv2 = Activation(activation='relu')(conv2)\n",
    "    \n",
    "    conv3 = Conv2DTranspose(int(depth/8), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv2)\n",
    "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "    conv3 = Activation(activation='relu')(conv3)\n",
    "\n",
    "    # Output layer\n",
    "    image = Conv2D(1, kernel_size=5, padding='same', \n",
    "                   activation='sigmoid')(conv3)\n",
    "\n",
    "    # Model definition    \n",
    "    model = Model(inputs=noise, outputs=image)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSiyoRcfcaca"
   },
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "XqZCl_Bacace",
    "outputId": "70ae0aa8-19a9-4b16-c1d7-5564f2983615"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfq_ISh-cack"
   },
   "source": [
    "#### Create adversarial network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M42c5nM8cacl"
   },
   "outputs": [],
   "source": [
    "z = Input(shape=(z_dimensions,))\n",
    "img = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCl7ji7-cacq"
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71sEohKlcacu"
   },
   "outputs": [],
   "source": [
    "pred = discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y59iXFpjcacy"
   },
   "outputs": [],
   "source": [
    "adversarial_model = Model(z, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3sxRe2Kcac2"
   },
   "outputs": [],
   "source": [
    "adversarial_model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=Nadam(lr=0.0004, \n",
    "                                            clipvalue=1.0), \n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04Zkz_OPcac5"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6yD1zoocac6"
   },
   "outputs": [],
   "source": [
    "def train(epochs=2000, batch=128, z_dim=z_dimensions):\n",
    "    \n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # sample real images: \n",
    "        real_imgs = np.reshape(\n",
    "            data[np.random.choice(data.shape[0],\n",
    "                                  batch,\n",
    "                                  replace=False)],\n",
    "            (batch,28,28,1))\n",
    "        \n",
    "        # generate fake images: \n",
    "        fake_imgs = generator.predict(\n",
    "            np.random.uniform(-1.0, 1.0, \n",
    "                              size=[batch, z_dim]))\n",
    "        \n",
    "        # concatenate images as discriminator inputs:\n",
    "        x = np.concatenate((real_imgs,fake_imgs))\n",
    "        \n",
    "        # assign y labels for discriminator: \n",
    "        y = np.ones([2*batch,1])\n",
    "        y[batch:,:] = 0\n",
    "        \n",
    "        # train discriminator: \n",
    "        d_metrics.append(\n",
    "            discriminator.train_on_batch(x,y)\n",
    "        )\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        \n",
    "        # adversarial net's noise input and \"real\" y: \n",
    "        noise = np.random.uniform(-1.0, 1.0, \n",
    "                                  size=[batch, z_dim])\n",
    "        y = np.ones([batch,1])\n",
    "        \n",
    "        # train adversarial net: \n",
    "        a_metrics.append(\n",
    "            adversarial_model.train_on_batch(noise,y)\n",
    "        ) \n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        # periodically print progress & fake images: \n",
    "        if (i+1)%100 == 0:\n",
    "\n",
    "            print('Epoch #{}'.format(i))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % \\\n",
    "            (i, running_d_loss/i, running_d_acc/i)\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % \\\n",
    "            (log_mesg, running_a_loss/i, running_a_acc/i)\n",
    "            print(log_mesg)\n",
    "\n",
    "            noise = np.random.uniform(-1.0, 1.0, \n",
    "                                      size=[16, z_dim])\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "\n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k+1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], \n",
    "                           cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return a_metrics, d_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lk9vvBI0cac_"
   },
   "source": [
    "_N.B.: Running the next cell leads to the following warning in recent versions of TensorFlow:_\n",
    "\n",
    "Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
    "\n",
    "_This warning can be safely ignored. In most neural networks, you should indeed ensure that you compile the model after adjusting whether the models weights are trainable or not. In a GAN, however, this is unnecessary: The discriminator need not be compiled after making its weights untrainable; instead, we compile these untrainable weights as a part of the adversarial model. You can read more about this unnecessary warning [here](https://github.com/keras-team/keras/issues/8585) and [here](https://github.com/tensorflow/tensorflow/issues/22012). If the warning **really** bothers you though, we created a GAN notebook with an awkward workaround [here](https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/awkward-GAN-with-no-warning.ipynb)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g5sO1sgXcadA",
    "outputId": "a6badb70-d36a-4188-fc5e-ab4911ea9ede"
   },
   "outputs": [],
   "source": [
    "a_metrics_complete, d_metrics_complete = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "K6RmEQ_2cadE",
    "outputId": "70665eae-9b82-47a3-b2f6-ba2bb7a9a36b"
   },
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Adversarial': [metric[0] for metric in a_metrics_complete],\n",
    "        'Discriminator': [metric[0] for metric in d_metrics_complete],\n",
    "    }\n",
    ").plot(title='Training Loss', logy=True)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "I_2zzzyAcadH",
    "outputId": "7793c2b4-4f9b-424e-a940-df40d64374c2"
   },
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Adversarial': [metric[1] for metric in a_metrics_complete],\n",
    "        'Discriminator': [metric[1] for metric in d_metrics_complete],\n",
    "    }\n",
    ").plot(title='Training Accuracy')\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjY1paSBcadL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "generative_adversarial_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
