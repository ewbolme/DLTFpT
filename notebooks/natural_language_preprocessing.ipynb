{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/natural_language_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqB8OkvED2is"
   },
   "source": [
    "# Natural Language Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82yPS6xUD2iw"
   },
   "source": [
    "In this notebook, we clean up a dataset of natural language data (books from Project Gutenberg) and use word2vec to embed the language in word vectors.\n",
    "\n",
    "**N.B.:** Some, all or none of these preprocessing steps may be helpful to a given downstream application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7R4Uwnb9D2i1"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GkOejk8D2i4",
    "outputId": "20a9329c-6dec-484a-bde1-e15d643735cb"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import spacy # for a lemmatization example\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import show, figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2TQZhYMD2jC"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfBCgMEpD2jG"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxebPPTwD2jM"
   },
   "outputs": [],
   "source": [
    "# a convenient method that handles newlines, as well as tokenizing sentences and words in one shot\n",
    "gberg_sents = gutenberg.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZcw28KBD2jT",
    "outputId": "908e4a58-34ee-4eab-804f-12884beb5973"
   },
   "outputs": [],
   "source": [
    "gberg_sents[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mT292uNZD2ja",
    "outputId": "f5274ffe-cac4-4254-d19d-9c83a46f1113"
   },
   "outputs": [],
   "source": [
    "gberg_sents[4][14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-rANNDAD2jf"
   },
   "source": [
    "#### Iteratively preprocess a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qbdicu2UD2jg"
   },
   "source": [
    "##### a tokenized sentence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPBHybu5D2ji",
    "outputId": "093e569d-020d-46fe-9631-490f62757b44"
   },
   "outputs": [],
   "source": [
    "gberg_sents[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qKOjLVQD2js"
   },
   "source": [
    "##### to lowercase: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tG1RqFu4D2jv",
    "outputId": "ac7b7f06-a5a2-4a3b-f65e-1bf631770315"
   },
   "outputs": [],
   "source": [
    "[w.lower() for w in gberg_sents[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQuxiLlpD2jz"
   },
   "source": [
    "##### remove stopwords and punctuation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBeQyTx1D2j0"
   },
   "outputs": [],
   "source": [
    "stpwrds = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78ZatfVvD2j7",
    "outputId": "7dd9e88b-b33a-4d0f-cd58-5ff7a3857244"
   },
   "outputs": [],
   "source": [
    "stpwrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBpZ70hfD2j_",
    "outputId": "f9044316-9889-49dd-de2b-c0aa22304aa1"
   },
   "outputs": [],
   "source": [
    "[w.lower() for w in gberg_sents[4] if w.lower() not in stpwrds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxZGIFcsD2kE"
   },
   "source": [
    "##### stem words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHxPVno5D2kF"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlWaERY1D2kK",
    "outputId": "8bd81b8b-de7b-4285-8379-ba505ff38430"
   },
   "outputs": [],
   "source": [
    "[stemmer.stem(w.lower()) for w in gberg_sents[4] if w.lower() not in stpwrds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbhFdJA7D2kP"
   },
   "source": [
    "##### a lemmatization example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ib1cBurCD2kQ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6Lm_W1uD2kV",
    "outputId": "969012c5-fdb0-4df3-9e13-a0e65b1a06be"
   },
   "outputs": [],
   "source": [
    "gutenberg.raw()[291:477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4s15u64D2ka"
   },
   "outputs": [],
   "source": [
    "spacy_doc = nlp(gutenberg.raw()[291:477])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLNqWRTFD2kk",
    "outputId": "ce5e2bb4-a05d-446c-ec68-63cc7aae4940"
   },
   "outputs": [],
   "source": [
    "[w.lemma_ for w in spacy_doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63aajPNvD2kq"
   },
   "source": [
    "##### handle bigram collocations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXsC0ZHRD2ks"
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(gberg_sents) # train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQ4OlbWSD2kv"
   },
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases) # create a more efficient Phraser object for transforming sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcxSpY9zD2ky",
    "outputId": "d2a9c1dd-d912-4287-a988-4d779e2b5301"
   },
   "outputs": [],
   "source": [
    "bigram.phrasegrams # output score of each bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5Pxtth-D2k1"
   },
   "outputs": [],
   "source": [
    "tokenized_sentence = \"Jon lives in New York City\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6BqNZelD2k6",
    "outputId": "00974221-3855-4ced-bbc9-73ddace3a363"
   },
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjwNwLNND2k9",
    "outputId": "765b6804-64a7-4945-c909-5384896d28e5"
   },
   "outputs": [],
   "source": [
    "bigram[tokenized_sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPqMIz_7D2k_"
   },
   "source": [
    "#### Preprocess the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMdwz_azD2lA"
   },
   "outputs": [],
   "source": [
    "# as in Maas et al. (2001):\n",
    "# - leave in stop words (\"indicative of sentiment\")\n",
    "# - no stemming (\"model learns similar representations of words of the same stem when data suggests it\")\n",
    "lower_sents = []\n",
    "for s in gberg_sents:\n",
    "    lower_sents.append([w.lower() for w in s if w.lower() not in list(string.punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CxI_qlgD2lE",
    "outputId": "e5d137f7-f6c1-4d13-d1aa-08b889f5f736"
   },
   "outputs": [],
   "source": [
    "lower_sents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3A3I79xdD2lH"
   },
   "outputs": [],
   "source": [
    "lower_bigram = Phraser(Phrases(lower_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTrKrOe0D2lL",
    "outputId": "9c168974-a2f1-4859-ea1a-4f21737609f0"
   },
   "outputs": [],
   "source": [
    "lower_bigram.phrasegrams # miss taylor, mr woodhouse, mr weston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ybi5gipND2lO",
    "outputId": "af362076-8cf8-4d19-e9f2-86e9ab18d4b0"
   },
   "outputs": [],
   "source": [
    "lower_bigram[\"jon lives in new york city\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U09EWf9mD2lQ",
    "outputId": "1da7bd0c-ed5a-4bdf-d62d-70b38de3fd00"
   },
   "outputs": [],
   "source": [
    "lower_bigram = Phraser(Phrases(lower_sents, min_count=32, threshold=64))\n",
    "lower_bigram.phrasegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4R1_1SR1D2lT"
   },
   "outputs": [],
   "source": [
    "clean_sents = []\n",
    "for s in lower_sents:\n",
    "    clean_sents.append(lower_bigram[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKfACtnMD2lV",
    "outputId": "9a6b8672-0db0-437e-c9b2-3956289a04da"
   },
   "outputs": [],
   "source": [
    "clean_sents[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN4phEN3D2lY",
    "outputId": "6af0c8f3-13ca-42c1-a49e-ec2c8da35c41"
   },
   "outputs": [],
   "source": [
    "clean_sents[6] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjVSAqGrD2la"
   },
   "source": [
    "#### Run word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urqHUfKRD2lb"
   },
   "outputs": [],
   "source": [
    "# max_vocab_size can be used instead of min_count (which has increased here)\n",
    "# model = Word2Vec(sentences=clean_sents, size=64, \n",
    "#                  sg=1, window=10, iter=5,\n",
    "#                  min_count=10, workers=4)\n",
    "# model.save('clean_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAilWnJQD2ld"
   },
   "source": [
    "#### Explore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RSQ5hf_D2lf"
   },
   "outputs": [],
   "source": [
    "# skip re-training the model with the next line:  \n",
    "model = gensim.models.Word2Vec.load('clean_gutenberg_model.w2v') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PApWCHC9D2lh",
    "outputId": "b34608b1-2e13-48c3-ffa8-32873c910342"
   },
   "outputs": [],
   "source": [
    "len(model.wv.vocab) # would be 17k if we carried out no preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVLwhd5yD2lj",
    "outputId": "300c615e-f2ca-4c77-b7e3-145d24a30381"
   },
   "outputs": [],
   "source": [
    "model.wv['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0BRAZjFD2lm",
    "outputId": "91018e1a-c932-4dd4-85c4-d7bef3f10d91"
   },
   "outputs": [],
   "source": [
    "len(model.wv['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-0nqxPWD2lp",
    "outputId": "4dd74b81-d386-4209-c5ef-a38dca2b938d"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('dog', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6hRq148D2lv",
    "outputId": "10ed8c3d-4629-4921-b6c1-86f6a91fedae"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('eat', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj-EWj2VD2ly",
    "outputId": "82ad3463-e985-483a-dc39-a3286318ae80"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('day', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_lh9E1ID2lz",
    "outputId": "45e71877-4b96-4110-830c-6c9abeab8752"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('father', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb3xOF-uD2l4",
    "outputId": "60ebc1d9-e597-44d9-f278-8f64b5c92acc"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('ma_am', topn=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XTkTA7_D2l6",
    "outputId": "70e4bd59-c481-4d8d-b6a3-5fe1b97039f6"
   },
   "outputs": [],
   "source": [
    "model.wv.doesnt_match(\"mother father sister brother dog\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYU_TDD8D2l8",
    "outputId": "81bb14bc-8765-416b-9835-6e42b2c2aec3"
   },
   "outputs": [],
   "source": [
    "model.wv.similarity('father', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e651y0mLD2l_",
    "outputId": "e338da1d-f560-4208-d316-4a7a190ebddc"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['father', 'woman'], negative=['man']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXxh9mjZD2mB",
    "outputId": "ab00bb89-4c67-4eae-808b-e47816f5f49c"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['husband', 'woman'], negative=['man']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA7stuqPD2mD"
   },
   "source": [
    "#### Reduce word vector dimensionality with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyiXoDGwD2mD"
   },
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAK8T2aXD2mF"
   },
   "outputs": [],
   "source": [
    "# X_2d = tsne.fit_transform(model.wv[model.wv.vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6bK8fcwD2mH"
   },
   "outputs": [],
   "source": [
    "# coords_df = pd.DataFrame(X_2d, columns=['x','y'])\n",
    "# coords_df['token'] = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kFPhL6pD2mJ"
   },
   "outputs": [],
   "source": [
    "# coords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJ7TjYS5D2mL"
   },
   "outputs": [],
   "source": [
    "# coords_df.to_csv('clean_gutenberg_tsne.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnJqkDUjD2mO"
   },
   "source": [
    "#### Visualise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HadiW80-D2mQ"
   },
   "outputs": [],
   "source": [
    "coords_df = pd.read_csv('clean_gutenberg_tsne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJMJXZfcD2mS",
    "outputId": "cb0d77bc-f631-4930-e835-ebf389366ae3"
   },
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_A2kOZXKD2mU"
   },
   "outputs": [],
   "source": [
    "subset_df = coords_df.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3ONcSEID2mY"
   },
   "outputs": [],
   "source": [
    "p = figure(plot_width=800, plot_height=800)\n",
    "_ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZCV28LGD2mZ",
    "outputId": "642ef5d0-2748-4df5-8da1-b12c54469892"
   },
   "outputs": [],
   "source": [
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "natural_language_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
